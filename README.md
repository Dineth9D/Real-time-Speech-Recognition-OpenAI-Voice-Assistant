# Real-time Speech Recognition + OpenAI Voice Assistant

![7426233460487  Converted -min](https://user-images.githubusercontent.com/49786334/218248352-0c121731-6f2a-4ce5-be0c-6c6f0f3bed56.jpg)


- This project implements real-time speech recognition and voice assistant application that utilizes the latest technology to provide seamless communication with OpenAI.

- Real-time speech recognition is a technology that allows a device to convert spoken language into text in real-time. With OpenAI we can communicate with a highly trained AI model which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer follow-up questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.

- AssemblyAI is typically achieved through the use of sophisticated algorithms and machine learning models that analyze sound waves and patterns to identify words and phrases.

- With AssemblyAI, OpenAI, and Python, this project promises a cutting-edge experience that you won't find anywhere else.

## Requirements

- AssemblyAI API Key
- Python 3.6 or above
- OpenAI API Key

# Steps that I followed

1. Set up a development environment: I chose Python programming language and set up the required tools and libraries to build the application.

2. Obtain an OpenAI API key: To access OpenAI's services, you need to sign up for an API key. This will allow you to make API requests to OpenAI and receive the required data for your application.

3. Integration of speech recognition: I used Assembly API for speech recognition. Also To access AssemblyAI's services, you need to sign up for an API key.

4. Processing of recognized speech: After speech recognition, you need to process the recognized speech and prepare it for sending to OpenAI API.

5. Integration of OpenAI API: Send the processed speech to OpenAI API and receive a response. The response will contain the data that you need to build a human voice assistant, such as a response text, response type, etc.

6. Integration of Assembly API: The Assembly API allows you to manage the user's context and track the user's conversation. You can use this API to keep track of the user's previous interactions, store user information, and make decisions about how to respond to the user.

7. Building the voice assistant: Using the data received from OpenAI API and Assembly API, you can build a voice assistant that can respond to user requests in real time. I used the command line for the user interface.

8. Testing and deployment: Test voice assistant thoroughly before deploying it to ensure that it works as expected.

## Libraries

These libraries ensure that the application performs efficiently and effectively, delivering accurate results in real-time.

- Pyaudio
- Websockets
- Asyncio
- Base64

![This is an image](https://myoctocat.com/assets/images/base-octocat.svg)

## Contributing

If you're interested in contributing to this project, you're in luck! Contributions are always welcome, and the development team is always eager to work with those who share their passion for technology. So, whether you have a problem that needs solving or would like to submit a pull request, don't hesitate to reach out.
